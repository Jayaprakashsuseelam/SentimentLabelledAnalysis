{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bedcf2e625377229",
   "metadata": {},
   "source": [
    "Import Libraries and Download NLTK Data"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "/**\n",
    "** Author : Jayaprakash\n",
    "**/"
   ],
   "id": "981046084af2927c"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2025-02-11T22:39:08.591574Z",
     "start_time": "2025-02-11T22:39:08.582533Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "\n",
    "# Download necessary NLTK data\n",
    "nltk.download('stopwords', quiet=True)\n",
    "nltk.download('wordnet', quiet=True)\n",
    "nltk.download('omw-1.4', quiet=True)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 21
  },
  {
   "cell_type": "markdown",
   "id": "76e478b050e37965",
   "metadata": {},
   "source": [
    "Define Text Preprocessing Function : \n",
    "This function cleans and preprocesses the text data by removing non-alphabetic characters, converting to lowercase, removing stopwords, and lemmatizing."
   ]
  },
  {
   "cell_type": "code",
   "id": "225a52038ebb09a1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-11T22:39:11.591538Z",
     "start_time": "2025-02-11T22:39:11.585024Z"
    }
   },
   "source": [
    "def text_preprocess(ds: pd.Series) -> pd.Series:\n",
    "    for i in range(len(ds)):\n",
    "        # Keep only alphabetic characters and replace others with a space\n",
    "        cleaned_text = re.sub('[^a-zA-Z]', ' ', ds[i])\n",
    "        # Convert to lowercase and split into individual words\n",
    "        words = cleaned_text.lower().split()\n",
    "        # Remove stopwords from the list of words\n",
    "        words = [word for word in words if word not in set(stopwords.words('english'))]\n",
    "\n",
    "        # Initialize lemmatizer and apply lemmatization to each word\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        words = [lemmatizer.lemmatize(word) for word in words if len(word) > 1]\n",
    "\n",
    "        # Join the processed words back into a single string\n",
    "        processed_text = ' '.join(words)\n",
    "        ds[i] = processed_text\n",
    "\n",
    "    return ds"
   ],
   "outputs": [],
   "execution_count": 22
  },
  {
   "cell_type": "markdown",
   "id": "452e606a9e4763df",
   "metadata": {},
   "source": [
    "Define Data Loading and Preprocessing Function : \n",
    "This function loads the dataset from a file, fills any NaN values, and applies the text preprocessing function."
   ]
  },
  {
   "cell_type": "code",
   "id": "d9f5c9a1f1d986d3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-11T22:39:14.237652Z",
     "start_time": "2025-02-11T22:39:14.233135Z"
    }
   },
   "source": [
    "def load_and_preprocess_data(file_path):\n",
    "    # Load the dataset from a tab-separated CSV file and specify column names\n",
    "    data = pd.read_csv(file_path, sep='\\t', header=None, names=['reviews', 'rating'])\n",
    "    \n",
    "    # Replace any missing values with 1\n",
    "    data.fillna(1, inplace=True)\n",
    "    \n",
    "    # Apply text preprocessing to the 'reviews' column\n",
    "    data['processed_reviews'] = text_preprocess(data['reviews'])\n",
    "    \n",
    "    return data"
   ],
   "outputs": [],
   "execution_count": 23
  },
  {
   "cell_type": "markdown",
   "id": "568c1cb4e98595ef",
   "metadata": {},
   "source": [
    "Define Classifier Training and Evaluation Function : \n",
    "This function vectorizes the text data, scales the features, trains multiple classifiers, and evaluates their performance."
   ]
  },
  {
   "cell_type": "code",
   "id": "22aba9cc3f15ad1d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-11T22:39:16.928802Z",
     "start_time": "2025-02-11T22:39:16.922453Z"
    }
   },
   "source": [
    "def train_and_evaluate_classifiers(X_train, X_test, y_train, y_test):\n",
    "\n",
    "    # Vectorize the text data using CountVectorizer\n",
    "    vectorizer = CountVectorizer()\n",
    "    X_train_vec = vectorizer.fit_transform(X_train)\n",
    "    X_test_vec = vectorizer.transform(X_test)\n",
    "\n",
    "    # Convert sparse matrices to dense arrays and scale the features\n",
    "    X_train_dense = X_train_vec.toarray()\n",
    "    X_test_dense = X_test_vec.toarray()\n",
    "    scaler = StandardScaler(with_mean=False)\n",
    "    X_train_scaled = scaler.fit_transform(X_train_dense)\n",
    "    X_test_scaled = scaler.transform(X_test_dense)\n",
    "\n",
    "    # Define the classifiers to be used\n",
    "    classifiers = {\n",
    "        'Naive Bayes': GaussianNB(),\n",
    "        'SVM': SVC(kernel='rbf'),\n",
    "        'KNN': KNeighborsClassifier(n_neighbors=5),\n",
    "        'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "        'Decision Tree': DecisionTreeClassifier(random_state=42)\n",
    "    }\n",
    "\n",
    "    evaluation_results = {}\n",
    "\n",
    "    # Train and evaluate each classifier\n",
    "    for name, model in classifiers.items():\n",
    "        # Use scaled data for classifiers that are sensitive to feature magnitude\n",
    "        if name in ['Naive Bayes', 'KNN', 'SVM']:\n",
    "            X_train_data = X_train_scaled\n",
    "            X_test_data = X_test_scaled\n",
    "        else:\n",
    "            X_train_data = X_train_vec\n",
    "            X_test_data = X_test_vec\n",
    "\n",
    "        # Fit the model and make predictions\n",
    "        model.fit(X_train_data, y_train)\n",
    "        y_pred = model.predict(X_test_data)\n",
    "\n",
    "        # Generate the classification report and store the results\n",
    "        report = classification_report(y_test, y_pred, output_dict=True)\n",
    "        evaluation_results[name] = report\n",
    "\n",
    "    return evaluation_results\n"
   ],
   "outputs": [],
   "execution_count": 24
  },
  {
   "cell_type": "markdown",
   "id": "f0f0a3dc12198d9a",
   "metadata": {},
   "source": [
    "Define Dataset Processing Function : \n",
    "This function processes a single dataset by loading, preprocessing, splitting the data, and training/evaluating classifiers."
   ]
  },
  {
   "cell_type": "code",
   "id": "6e5940c205d699a1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-11T22:37:04.791408Z",
     "start_time": "2025-02-11T22:37:04.784996Z"
    }
   },
   "source": [
    "def process_dataset(file_path, dataset_name):\n",
    "    print(f\"\\nProcessing the {dataset_name} dataset...\")\n",
    "    \n",
    "    # Load and preprocess the dataset\n",
    "    dataset = load_and_preprocess_data(file_path)\n",
    "    X = dataset['processed_reviews']\n",
    "    y = dataset['rating']\n",
    "\n",
    "    # Split the dataset into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Train and evaluate the classifiers\n",
    "    results = train_and_evaluate_classifiers(X_train, X_test, y_train, y_test)\n",
    "\n",
    "    # Display the results for each classifier\n",
    "    print(f\"\\nEvaluation results for {dataset_name}:\")\n",
    "    for clf_name, report in results.items():\n",
    "        print(f\"\\nClassifier: {clf_name}\")\n",
    "        print(f\"Accuracy: {report['accuracy']:.2f}\")\n",
    "        print(f\"Macro Avg Precision: {report['macro avg']['precision']:.2f}\")\n",
    "        print(f\"Macro Avg Recall: {report['macro avg']['recall']:.2f}\")\n",
    "        print(f\"Macro Avg F1-Score: {report['macro avg']['f1-score']:.2f}\")\n",
    "\n",
    "    return results"
   ],
   "outputs": [],
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "id": "2ce083d9a25f72b9",
   "metadata": {},
   "source": [
    "Process All Datasets and Compare Results : \n",
    "This section processes all three datasets and compares the performance of classifiers across datasets."
   ]
  },
  {
   "cell_type": "code",
   "id": "c0b9ccedf1e83d01",
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-02-11T22:39:36.045561Z"
    }
   },
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# List of datasets with corresponding names\n",
    "datasets = [\n",
    "    ('imdb_labelled.txt', 'IMDB'),\n",
    "    ('amazon_cells_labelled.txt', 'Amazon'),\n",
    "    ('yelp_labelled.txt', 'Yelp')\n",
    "]\n",
    "\n",
    "# Process each dataset and store results\n",
    "all_results = {}\n",
    "for file_path, dataset_name in datasets:\n",
    "    all_results[dataset_name] = process_dataset(file_path, dataset_name)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing the IMDB dataset...\n",
      "\n",
      "Evaluation results for IMDB:\n",
      "\n",
      "Classifier: Naive Bayes\n",
      "Accuracy: 0.65\n",
      "Macro Avg Precision: 0.66\n",
      "Macro Avg Recall: 0.64\n",
      "Macro Avg F1-Score: 0.64\n",
      "\n",
      "Classifier: SVM\n",
      "Accuracy: 0.66\n",
      "Macro Avg Precision: 0.72\n",
      "Macro Avg Recall: 0.66\n",
      "Macro Avg F1-Score: 0.63\n",
      "\n",
      "Classifier: KNN\n",
      "Accuracy: 0.55\n",
      "Macro Avg Precision: 0.69\n",
      "Macro Avg Recall: 0.56\n",
      "Macro Avg F1-Score: 0.46\n",
      "\n",
      "Classifier: Random Forest\n",
      "Accuracy: 0.69\n",
      "Macro Avg Precision: 0.72\n",
      "Macro Avg Recall: 0.70\n",
      "Macro Avg F1-Score: 0.69\n",
      "\n",
      "Classifier: Decision Tree\n",
      "Accuracy: 0.65\n",
      "Macro Avg Precision: 0.66\n",
      "Macro Avg Recall: 0.65\n",
      "Macro Avg F1-Score: 0.65\n",
      "\n",
      "Processing the Amazon dataset...\n",
      "\n",
      "Evaluation results for Amazon:\n",
      "\n",
      "Classifier: Naive Bayes\n",
      "Accuracy: 0.69\n",
      "Macro Avg Precision: 0.69\n",
      "Macro Avg Recall: 0.69\n",
      "Macro Avg F1-Score: 0.69\n",
      "\n",
      "Classifier: SVM\n",
      "Accuracy: 0.74\n",
      "Macro Avg Precision: 0.75\n",
      "Macro Avg Recall: 0.74\n",
      "Macro Avg F1-Score: 0.74\n",
      "\n",
      "Classifier: KNN\n",
      "Accuracy: 0.70\n",
      "Macro Avg Precision: 0.72\n",
      "Macro Avg Recall: 0.69\n",
      "Macro Avg F1-Score: 0.69\n",
      "\n",
      "Classifier: Random Forest\n",
      "Accuracy: 0.79\n",
      "Macro Avg Precision: 0.79\n",
      "Macro Avg Recall: 0.79\n",
      "Macro Avg F1-Score: 0.78\n",
      "\n",
      "Classifier: Decision Tree\n",
      "Accuracy: 0.77\n",
      "Macro Avg Precision: 0.77\n",
      "Macro Avg Recall: 0.77\n",
      "Macro Avg F1-Score: 0.76\n",
      "\n",
      "Processing the Yelp dataset...\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "78140815a21fb00e",
   "metadata": {},
   "source": [
    "Compare Performances across Datasets"
   ]
  },
  {
   "cell_type": "code",
   "id": "b7b6d8a02d1e11a0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-11T22:37:29.058058Z",
     "start_time": "2025-02-11T22:37:29.050501Z"
    }
   },
   "source": [
    "print(\"\\n\\nComparison of classifier performance across datasets:\")\n",
    "for clf_name in all_results['IMDB'].keys():\n",
    "    print(f\"\\n{clf_name}:\")\n",
    "    for dataset_name in all_results.keys():\n",
    "        accuracy = all_results[dataset_name][clf_name]['accuracy']\n",
    "        precision=all_results[dataset_name][clf_name]['macro avg']['precision']\n",
    "        recall = all_results[dataset_name][clf_name]['macro avg']['recall']\n",
    "        f1_score = all_results[dataset_name][clf_name]['macro avg']['f1-score']\n",
    "        print(f\"  {dataset_name:<10} - Accuracy: {accuracy:.2f}, Precision: {precision:.2f}, Recall: {recall:.2f}, F1-score: {f1_score:.2f}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Comparison of classifier performance across datasets:\n",
      "\n",
      "Naive Bayes:\n",
      "  IMDB       - Accuracy: 0.65, Precision: 0.66, Recall: 0.64, F1-score: 0.64\n",
      "  Amazon     - Accuracy: 0.69, Precision: 0.69, Recall: 0.69, F1-score: 0.69\n",
      "  Yelp       - Accuracy: 0.67, Precision: 0.68, Recall: 0.66, F1-score: 0.65\n",
      "\n",
      "SVM:\n",
      "  IMDB       - Accuracy: 0.66, Precision: 0.72, Recall: 0.66, F1-score: 0.63\n",
      "  Amazon     - Accuracy: 0.74, Precision: 0.75, Recall: 0.74, F1-score: 0.74\n",
      "  Yelp       - Accuracy: 0.69, Precision: 0.70, Recall: 0.68, F1-score: 0.68\n",
      "\n",
      "KNN:\n",
      "  IMDB       - Accuracy: 0.55, Precision: 0.69, Recall: 0.56, F1-score: 0.46\n",
      "  Amazon     - Accuracy: 0.70, Precision: 0.72, Recall: 0.69, F1-score: 0.69\n",
      "  Yelp       - Accuracy: 0.62, Precision: 0.63, Recall: 0.63, F1-score: 0.62\n",
      "\n",
      "Random Forest:\n",
      "  IMDB       - Accuracy: 0.69, Precision: 0.72, Recall: 0.70, F1-score: 0.69\n",
      "  Amazon     - Accuracy: 0.79, Precision: 0.79, Recall: 0.79, F1-score: 0.78\n",
      "  Yelp       - Accuracy: 0.70, Precision: 0.72, Recall: 0.71, F1-score: 0.70\n",
      "\n",
      "Decision Tree:\n",
      "  IMDB       - Accuracy: 0.65, Precision: 0.66, Recall: 0.65, F1-score: 0.65\n",
      "  Amazon     - Accuracy: 0.77, Precision: 0.77, Recall: 0.77, F1-score: 0.76\n",
      "  Yelp       - Accuracy: 0.73, Precision: 0.74, Recall: 0.73, F1-score: 0.73\n"
     ]
    }
   ],
   "execution_count": 19
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
